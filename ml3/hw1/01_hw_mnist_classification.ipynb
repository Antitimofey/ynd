{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация MNIST\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/girafe_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обратимся к классической задаче распознавания рукописных цифр. Мы будем работать с набором данных [MNIST](http://yann.lecun.com/exdb/mnist/). В этом задании мы воспользуемся всем датасетом целиком.\n",
    "\n",
    "__Ваша основная задача: реализовать весь пайплайн обучения модели и добиться качества $\\geq 92\\%$ на тестовой выборке.__\n",
    "\n",
    "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбуку с первого занятия.\n",
    "\n",
    "Мы настоятельно рекомендуем писать код «с нуля», лишь изредка подглядывая в готовые примеры, а не просто «копировать-вставлять». Это поможет вам в будущем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_mnist_data = MNIST('.', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test_mnist_data = MNIST('.', train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True,# Creating model instance\n",
    "model = None # your code here\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_mnist_data,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f'Image label: {_label}')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте модель, представленную ниже. Пожалуйста, не создавайте чрезмерно сложную сеть — она не должна быть глубже четырёх слоёв (можно и меньше). Ваша основная задача — обучить модель и добиться как минимум 92% точности на тестовой выборке (hold-out выборке).\n",
    "\n",
    "*Примечание: линейных слоёв и функций активации должно быть достаточно.*\n",
    "\n",
    "__Обратите внимание, ваша модель должна быть представлена переменной `model`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "device = 'cpu'\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            #nn.Linear(512, 512),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже доступны локальные тесты для проверки вашей модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model is not None, 'Please, use `model` variable to store your model'\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].reshape(-1, 784)\n",
    "    y = random_batch[1]\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model(x)    \n",
    "except Exception as e:\n",
    "    print('Something is wrong with the model')\n",
    "    raise e\n",
    "    \n",
    "    \n",
    "assert y_predicted.shape[-1] == 10, 'Model should predict 10 logits/probas'\n",
    "\n",
    "print('Everything seems fine!')\n",
    "# __________end of block__________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите модель на обучающей выборке. Рекомендуем поэкспериментировать с различными оптимизаторами.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.577219  [   32/60000]\n",
      "loss: 0.247707  [ 3232/60000]\n",
      "loss: 0.511131  [ 6432/60000]\n",
      "loss: 0.360351  [ 9632/60000]\n",
      "loss: 0.501241  [12832/60000]\n",
      "loss: 0.295582  [16032/60000]\n",
      "loss: 0.336279  [19232/60000]\n",
      "loss: 0.572435  [22432/60000]\n",
      "loss: 0.425005  [25632/60000]\n",
      "loss: 0.134186  [28832/60000]\n",
      "loss: 0.423668  [32032/60000]\n",
      "loss: 0.549270  [35232/60000]\n",
      "loss: 0.215406  [38432/60000]\n",
      "loss: 0.250068  [41632/60000]\n",
      "loss: 0.293251  [44832/60000]\n",
      "loss: 0.789753  [48032/60000]\n",
      "loss: 0.243933  [51232/60000]\n",
      "loss: 0.290468  [54432/60000]\n",
      "loss: 0.269816  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.7%, Avg loss: 0.383692 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.299556  [   32/60000]\n",
      "loss: 0.561950  [ 3232/60000]\n",
      "loss: 0.300867  [ 6432/60000]\n",
      "loss: 0.355931  [ 9632/60000]\n",
      "loss: 0.475037  [12832/60000]\n",
      "loss: 0.589831  [16032/60000]\n",
      "loss: 0.194602  [19232/60000]\n",
      "loss: 0.334131  [22432/60000]\n",
      "loss: 0.325352  [25632/60000]\n",
      "loss: 0.364168  [28832/60000]\n",
      "loss: 0.542586  [32032/60000]\n",
      "loss: 0.355079  [35232/60000]\n",
      "loss: 0.369151  [38432/60000]\n",
      "loss: 0.577407  [41632/60000]\n",
      "loss: 0.313315  [44832/60000]\n",
      "loss: 0.270930  [48032/60000]\n",
      "loss: 0.296292  [51232/60000]\n",
      "loss: 0.369538  [54432/60000]\n",
      "loss: 0.354188  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.371962 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.354631  [   32/60000]\n",
      "loss: 0.407051  [ 3232/60000]\n",
      "loss: 0.354685  [ 6432/60000]\n",
      "loss: 0.283751  [ 9632/60000]\n",
      "loss: 0.381896  [12832/60000]\n",
      "loss: 0.386945  [16032/60000]\n",
      "loss: 0.238866  [19232/60000]\n",
      "loss: 0.358463  [22432/60000]\n",
      "loss: 0.537043  [25632/60000]\n",
      "loss: 0.357557  [28832/60000]\n",
      "loss: 0.262746  [32032/60000]\n",
      "loss: 0.210133  [35232/60000]\n",
      "loss: 0.294968  [38432/60000]\n",
      "loss: 0.518241  [41632/60000]\n",
      "loss: 0.323125  [44832/60000]\n",
      "loss: 0.257661  [48032/60000]\n",
      "loss: 0.361426  [51232/60000]\n",
      "loss: 0.277674  [54432/60000]\n",
      "loss: 0.532298  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.362066 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.257728  [   32/60000]\n",
      "loss: 0.253850  [ 3232/60000]\n",
      "loss: 0.483377  [ 6432/60000]\n",
      "loss: 0.326788  [ 9632/60000]\n",
      "loss: 0.322588  [12832/60000]\n",
      "loss: 0.258322  [16032/60000]\n",
      "loss: 0.417870  [19232/60000]\n",
      "loss: 0.284617  [22432/60000]\n",
      "loss: 0.576039  [25632/60000]\n",
      "loss: 0.314408  [28832/60000]\n",
      "loss: 0.571131  [32032/60000]\n",
      "loss: 0.336080  [35232/60000]\n",
      "loss: 0.450892  [38432/60000]\n",
      "loss: 0.419495  [41632/60000]\n",
      "loss: 0.242114  [44832/60000]\n",
      "loss: 0.533816  [48032/60000]\n",
      "loss: 0.438008  [51232/60000]\n",
      "loss: 0.335009  [54432/60000]\n",
      "loss: 0.392334  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.353879 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.479022  [   32/60000]\n",
      "loss: 0.263422  [ 3232/60000]\n",
      "loss: 0.401848  [ 6432/60000]\n",
      "loss: 0.222454  [ 9632/60000]\n",
      "loss: 0.301315  [12832/60000]\n",
      "loss: 0.589819  [16032/60000]\n",
      "loss: 0.340034  [19232/60000]\n",
      "loss: 0.382046  [22432/60000]\n",
      "loss: 0.308398  [25632/60000]\n",
      "loss: 0.347361  [28832/60000]\n",
      "loss: 0.389631  [32032/60000]\n",
      "loss: 0.332945  [35232/60000]\n",
      "loss: 0.420670  [38432/60000]\n",
      "loss: 0.240870  [41632/60000]\n",
      "loss: 0.584231  [44832/60000]\n",
      "loss: 0.340067  [48032/60000]\n",
      "loss: 0.266897  [51232/60000]\n",
      "loss: 0.531365  [54432/60000]\n",
      "loss: 0.302483  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.346258 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.266923  [   32/60000]\n",
      "loss: 0.283475  [ 3232/60000]\n",
      "loss: 0.249248  [ 6432/60000]\n",
      "loss: 0.382672  [ 9632/60000]\n",
      "loss: 0.435469  [12832/60000]\n",
      "loss: 0.580792  [16032/60000]\n",
      "loss: 0.230193  [19232/60000]\n",
      "loss: 0.285435  [22432/60000]\n",
      "loss: 0.204544  [25632/60000]\n",
      "loss: 0.514477  [28832/60000]\n",
      "loss: 0.349477  [32032/60000]\n",
      "loss: 0.470035  [35232/60000]\n",
      "loss: 0.491796  [38432/60000]\n",
      "loss: 0.238840  [41632/60000]\n",
      "loss: 0.234924  [44832/60000]\n",
      "loss: 0.441107  [48032/60000]\n",
      "loss: 0.433811  [51232/60000]\n",
      "loss: 0.332204  [54432/60000]\n",
      "loss: 0.159494  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.5%, Avg loss: 0.338933 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.655977  [   32/60000]\n",
      "loss: 0.232869  [ 3232/60000]\n",
      "loss: 0.328982  [ 6432/60000]\n",
      "loss: 0.443906  [ 9632/60000]\n",
      "loss: 0.370894  [12832/60000]\n",
      "loss: 0.445055  [16032/60000]\n",
      "loss: 0.217648  [19232/60000]\n",
      "loss: 0.601644  [22432/60000]\n",
      "loss: 0.270844  [25632/60000]\n",
      "loss: 0.283723  [28832/60000]\n",
      "loss: 0.208745  [32032/60000]\n",
      "loss: 0.420355  [35232/60000]\n",
      "loss: 0.367987  [38432/60000]\n",
      "loss: 0.260558  [41632/60000]\n",
      "loss: 0.433705  [44832/60000]\n",
      "loss: 0.247251  [48032/60000]\n",
      "loss: 0.395445  [51232/60000]\n",
      "loss: 0.541541  [54432/60000]\n",
      "loss: 0.398126  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.333212 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.399298  [   32/60000]\n",
      "loss: 0.366861  [ 3232/60000]\n",
      "loss: 0.194116  [ 6432/60000]\n",
      "loss: 0.318133  [ 9632/60000]\n",
      "loss: 0.557451  [12832/60000]\n",
      "loss: 0.764427  [16032/60000]\n",
      "loss: 0.265968  [19232/60000]\n",
      "loss: 0.500416  [22432/60000]\n",
      "loss: 0.296349  [25632/60000]\n",
      "loss: 0.423888  [28832/60000]\n",
      "loss: 0.322031  [32032/60000]\n",
      "loss: 0.513067  [35232/60000]\n",
      "loss: 0.189007  [38432/60000]\n",
      "loss: 0.165382  [41632/60000]\n",
      "loss: 0.218909  [44832/60000]\n",
      "loss: 0.201789  [48032/60000]\n",
      "loss: 0.306736  [51232/60000]\n",
      "loss: 0.243074  [54432/60000]\n",
      "loss: 0.294538  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.328041 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.281617  [   32/60000]\n",
      "loss: 0.395820  [ 3232/60000]\n",
      "loss: 0.269318  [ 6432/60000]\n",
      "loss: 0.096695  [ 9632/60000]\n",
      "loss: 0.152298  [12832/60000]\n",
      "loss: 0.327376  [16032/60000]\n",
      "loss: 0.183496  [19232/60000]\n",
      "loss: 0.328598  [22432/60000]\n",
      "loss: 0.168388  [25632/60000]\n",
      "loss: 0.444331  [28832/60000]\n",
      "loss: 0.221988  [32032/60000]\n",
      "loss: 0.313947  [35232/60000]\n",
      "loss: 0.381079  [38432/60000]\n",
      "loss: 0.451033  [41632/60000]\n",
      "loss: 0.197525  [44832/60000]\n",
      "loss: 0.140465  [48032/60000]\n",
      "loss: 0.306976  [51232/60000]\n",
      "loss: 0.419311  [54432/60000]\n",
      "loss: 0.297126  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.322789 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.523515  [   32/60000]\n",
      "loss: 0.307359  [ 3232/60000]\n",
      "loss: 0.349277  [ 6432/60000]\n",
      "loss: 0.255955  [ 9632/60000]\n",
      "loss: 0.296392  [12832/60000]\n",
      "loss: 0.260034  [16032/60000]\n",
      "loss: 0.213329  [19232/60000]\n",
      "loss: 0.369158  [22432/60000]\n",
      "loss: 0.199160  [25632/60000]\n",
      "loss: 0.323663  [28832/60000]\n",
      "loss: 0.411378  [32032/60000]\n",
      "loss: 0.364543  [35232/60000]\n",
      "loss: 0.492466  [38432/60000]\n",
      "loss: 0.316480  [41632/60000]\n",
      "loss: 0.213928  [44832/60000]\n",
      "loss: 0.347150  [48032/60000]\n",
      "loss: 0.430562  [51232/60000]\n",
      "loss: 0.183900  [54432/60000]\n",
      "loss: 0.347198  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.318272 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.610473  [   32/60000]\n",
      "loss: 0.407103  [ 3232/60000]\n",
      "loss: 0.637188  [ 6432/60000]\n",
      "loss: 0.360672  [ 9632/60000]\n",
      "loss: 0.203696  [12832/60000]\n",
      "loss: 0.236245  [16032/60000]\n",
      "loss: 0.426362  [19232/60000]\n",
      "loss: 0.254980  [22432/60000]\n",
      "loss: 0.211268  [25632/60000]\n",
      "loss: 0.232774  [28832/60000]\n",
      "loss: 0.243353  [32032/60000]\n",
      "loss: 0.522691  [35232/60000]\n",
      "loss: 0.275515  [38432/60000]\n",
      "loss: 0.296261  [41632/60000]\n",
      "loss: 0.169201  [44832/60000]\n",
      "loss: 0.415624  [48032/60000]\n",
      "loss: 0.425205  [51232/60000]\n",
      "loss: 0.374328  [54432/60000]\n",
      "loss: 0.370409  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.313651 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.333219  [   32/60000]\n",
      "loss: 0.194605  [ 3232/60000]\n",
      "loss: 0.171263  [ 6432/60000]\n",
      "loss: 0.532356  [ 9632/60000]\n",
      "loss: 0.280519  [12832/60000]\n",
      "loss: 0.318351  [16032/60000]\n",
      "loss: 0.422471  [19232/60000]\n",
      "loss: 0.323126  [22432/60000]\n",
      "loss: 0.148942  [25632/60000]\n",
      "loss: 0.501611  [28832/60000]\n",
      "loss: 0.280747  [32032/60000]\n",
      "loss: 0.395120  [35232/60000]\n",
      "loss: 0.525082  [38432/60000]\n",
      "loss: 0.217862  [41632/60000]\n",
      "loss: 0.336944  [44832/60000]\n",
      "loss: 0.171158  [48032/60000]\n",
      "loss: 0.245621  [51232/60000]\n",
      "loss: 0.281593  [54432/60000]\n",
      "loss: 0.296115  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.309812 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.366559  [   32/60000]\n",
      "loss: 0.210707  [ 3232/60000]\n",
      "loss: 0.217855  [ 6432/60000]\n",
      "loss: 0.365946  [ 9632/60000]\n",
      "loss: 0.146720  [12832/60000]\n",
      "loss: 0.211131  [16032/60000]\n",
      "loss: 0.259804  [19232/60000]\n",
      "loss: 0.206484  [22432/60000]\n",
      "loss: 0.286432  [25632/60000]\n",
      "loss: 0.215785  [28832/60000]\n",
      "loss: 0.167816  [32032/60000]\n",
      "loss: 0.390963  [35232/60000]\n",
      "loss: 0.260506  [38432/60000]\n",
      "loss: 0.196217  [41632/60000]\n",
      "loss: 0.305226  [44832/60000]\n",
      "loss: 0.231801  [48032/60000]\n",
      "loss: 0.683666  [51232/60000]\n",
      "loss: 0.176830  [54432/60000]\n",
      "loss: 0.305020  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.306251 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.230348  [   32/60000]\n",
      "loss: 0.475702  [ 3232/60000]\n",
      "loss: 0.470426  [ 6432/60000]\n",
      "loss: 0.167997  [ 9632/60000]\n",
      "loss: 0.433726  [12832/60000]\n",
      "loss: 0.263958  [16032/60000]\n",
      "loss: 0.224208  [19232/60000]\n",
      "loss: 0.657792  [22432/60000]\n",
      "loss: 0.195724  [25632/60000]\n",
      "loss: 0.158471  [28832/60000]\n",
      "loss: 0.182494  [32032/60000]\n",
      "loss: 0.249624  [35232/60000]\n",
      "loss: 0.460779  [38432/60000]\n",
      "loss: 0.268492  [41632/60000]\n",
      "loss: 0.195437  [44832/60000]\n",
      "loss: 0.684906  [48032/60000]\n",
      "loss: 0.242930  [51232/60000]\n",
      "loss: 0.410796  [54432/60000]\n",
      "loss: 0.378833  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.303026 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.428600  [   32/60000]\n",
      "loss: 0.367523  [ 3232/60000]\n",
      "loss: 0.246889  [ 6432/60000]\n",
      "loss: 0.480672  [ 9632/60000]\n",
      "loss: 0.211642  [12832/60000]\n",
      "loss: 0.210818  [16032/60000]\n",
      "loss: 0.751118  [19232/60000]\n",
      "loss: 0.335948  [22432/60000]\n",
      "loss: 0.166418  [25632/60000]\n",
      "loss: 0.488904  [28832/60000]\n",
      "loss: 0.131605  [32032/60000]\n",
      "loss: 0.317161  [35232/60000]\n",
      "loss: 0.398195  [38432/60000]\n",
      "loss: 0.174070  [41632/60000]\n",
      "loss: 0.526704  [44832/60000]\n",
      "loss: 0.356874  [48032/60000]\n",
      "loss: 0.326333  [51232/60000]\n",
      "loss: 0.129366  [54432/60000]\n",
      "loss: 0.215131  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.299395 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.215837  [   32/60000]\n",
      "loss: 0.343620  [ 3232/60000]\n",
      "loss: 0.153280  [ 6432/60000]\n",
      "loss: 0.424191  [ 9632/60000]\n",
      "loss: 0.319283  [12832/60000]\n",
      "loss: 0.242470  [16032/60000]\n",
      "loss: 0.387347  [19232/60000]\n",
      "loss: 0.335700  [22432/60000]\n",
      "loss: 0.317464  [25632/60000]\n",
      "loss: 0.171402  [28832/60000]\n",
      "loss: 0.208191  [32032/60000]\n",
      "loss: 0.229052  [35232/60000]\n",
      "loss: 0.110776  [38432/60000]\n",
      "loss: 0.111046  [41632/60000]\n",
      "loss: 0.292164  [44832/60000]\n",
      "loss: 0.146960  [48032/60000]\n",
      "loss: 0.101931  [51232/60000]\n",
      "loss: 0.467404  [54432/60000]\n",
      "loss: 0.208913  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.296224 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.395552  [   32/60000]\n",
      "loss: 0.136845  [ 3232/60000]\n",
      "loss: 0.427126  [ 6432/60000]\n",
      "loss: 0.243442  [ 9632/60000]\n",
      "loss: 0.146091  [12832/60000]\n",
      "loss: 0.443589  [16032/60000]\n",
      "loss: 0.237804  [19232/60000]\n",
      "loss: 0.262730  [22432/60000]\n",
      "loss: 0.413191  [25632/60000]\n",
      "loss: 0.362617  [28832/60000]\n",
      "loss: 0.588186  [32032/60000]\n",
      "loss: 0.182373  [35232/60000]\n",
      "loss: 0.659204  [38432/60000]\n",
      "loss: 0.234732  [41632/60000]\n",
      "loss: 0.223172  [44832/60000]\n",
      "loss: 0.278002  [48032/60000]\n",
      "loss: 0.213715  [51232/60000]\n",
      "loss: 0.359426  [54432/60000]\n",
      "loss: 0.159280  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.293294 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.157107  [   32/60000]\n",
      "loss: 0.171465  [ 3232/60000]\n",
      "loss: 0.187057  [ 6432/60000]\n",
      "loss: 0.419884  [ 9632/60000]\n",
      "loss: 0.507757  [12832/60000]\n",
      "loss: 0.232471  [16032/60000]\n",
      "loss: 0.492769  [19232/60000]\n",
      "loss: 0.192270  [22432/60000]\n",
      "loss: 0.310473  [25632/60000]\n",
      "loss: 0.242244  [28832/60000]\n",
      "loss: 0.292685  [32032/60000]\n",
      "loss: 0.119391  [35232/60000]\n",
      "loss: 0.267024  [38432/60000]\n",
      "loss: 0.298084  [41632/60000]\n",
      "loss: 0.389671  [44832/60000]\n",
      "loss: 0.147094  [48032/60000]\n",
      "loss: 0.273517  [51232/60000]\n",
      "loss: 0.264967  [54432/60000]\n",
      "loss: 0.114722  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.290487 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.108590  [   32/60000]\n",
      "loss: 0.330003  [ 3232/60000]\n",
      "loss: 0.157497  [ 6432/60000]\n",
      "loss: 0.202712  [ 9632/60000]\n",
      "loss: 0.246397  [12832/60000]\n",
      "loss: 0.301848  [16032/60000]\n",
      "loss: 0.283288  [19232/60000]\n",
      "loss: 0.435498  [22432/60000]\n",
      "loss: 0.325290  [25632/60000]\n",
      "loss: 0.489930  [28832/60000]\n",
      "loss: 0.094210  [32032/60000]\n",
      "loss: 0.399209  [35232/60000]\n",
      "loss: 0.471218  [38432/60000]\n",
      "loss: 0.180702  [41632/60000]\n",
      "loss: 0.086839  [44832/60000]\n",
      "loss: 0.205615  [48032/60000]\n",
      "loss: 0.211502  [51232/60000]\n",
      "loss: 0.176485  [54432/60000]\n",
      "loss: 0.154248  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.287406 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.337849  [   32/60000]\n",
      "loss: 0.290169  [ 3232/60000]\n",
      "loss: 0.382748  [ 6432/60000]\n",
      "loss: 0.477482  [ 9632/60000]\n",
      "loss: 0.144303  [12832/60000]\n",
      "loss: 0.260845  [16032/60000]\n",
      "loss: 0.326246  [19232/60000]\n",
      "loss: 0.338811  [22432/60000]\n",
      "loss: 0.337536  [25632/60000]\n",
      "loss: 0.203922  [28832/60000]\n",
      "loss: 0.152687  [32032/60000]\n",
      "loss: 0.129750  [35232/60000]\n",
      "loss: 0.377659  [38432/60000]\n",
      "loss: 0.144821  [41632/60000]\n",
      "loss: 0.402150  [44832/60000]\n",
      "loss: 0.379256  [48032/60000]\n",
      "loss: 0.392580  [51232/60000]\n",
      "loss: 0.325966  [54432/60000]\n",
      "loss: 0.438887  [57632/60000]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.284592 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_data_loader, model, loss_fn, optimizer)\n",
    "    test(test_data_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также помните, что вы всегда можете обратиться к отличной [документации](https://pytorch.org/docs/stable/index.html) и [учебным материалам](https://pytorch.org/tutorials/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in train_data_loader:\n",
    "        y_predicted = model(batch[0].reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.91637\n"
     ]
    }
   ],
   "source": [
    "print(f'Neural network accuracy on train set: {train_acc:3.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "real_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_data_loader:\n",
    "        y_predicted = model(batch[0].reshape(-1, 784))\n",
    "        predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "        real_labels.append(batch[1])\n",
    "\n",
    "predicted_labels = torch.cat(predicted_labels)\n",
    "real_labels = torch.cat(real_labels)\n",
    "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.92\n"
     ]
    }
   ],
   "source": [
    "print(f'Neural network accuracy on test set: {test_acc:3.5}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert test_acc >= 0.92, 'Test accuracy is below 0.92 threshold'\n",
    "assert train_acc >= 0.91, 'Train accuracy is below 0.91 while test accuracy is fine. We recommend to check your model and data flow'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model`, а файл `hw_mnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to `submission_dict_mnist_task_1.json`\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import os\n",
    "import json\n",
    "assert os.path.exists('hw_mnist_data_dict.npy'), 'Please, download `hw_mnist_data_dict.npy` and place it in the working directory'\n",
    "\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "    \n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx:idx+step].reshape(-1, 784))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1))\n",
    "    \n",
    "    predicted_labels = torch.cat(predicted_labels).numpy()\n",
    "    predicted_labels = ','.join([str(x) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "loaded_data_dict = np.load('hw_mnist_data_dict.npy', allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    'train': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['train'])),\n",
    "    'test': get_predictions(model, torch.FloatTensor(loaded_data_dict.item()['test']))\n",
    "}\n",
    "\n",
    "with open('submission_dict_mnist_task_1.json', 'w') as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print('File saved to `submission_dict_mnist_task_1.json`')\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сдача задания\n",
    "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
    "    \n",
    "* `submission_dict_mnist_task_1.json` в задачу Warmup (hw_mnist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlhw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
