{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDsVMGiVgSq2"
   },
   "source": [
    "## Переобучение нейронных сетей и борьба с ним\n",
    "\n",
    "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/girafe_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3isBRG6PgSq6"
   },
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "def args_and_kwargs(*args, **kwargs):\n",
    "    return args, kwargs\n",
    "\n",
    "def parse_pytorch_model(model_str):\n",
    "    def parse_layer(layer_str):\n",
    "        layer_name, params = layer_str.split(\"(\", 1)\n",
    "        layer_info = {\"type\": layer_name.strip()}\n",
    "        params_template = layer_str.replace(layer_name, \"args_and_kwargs\")\n",
    "        \n",
    "        param_dict = {}\n",
    "        if len(params):\n",
    "            args, kwargs = eval(params_template)\n",
    "            if len(args) or len(kwargs):\n",
    "                param_dict[\"args\"] = args\n",
    "                for name, value in kwargs.items():\n",
    "                    param_dict[name] = value\n",
    "        layer_info[\"parameters\"] = param_dict\n",
    "        return layer_info\n",
    "\n",
    "    model_dict = {}\n",
    "    lines = model_str.splitlines()\n",
    "    model_name = lines[0].strip(\"()\")\n",
    "    model_dict[\"model_name\"] = model_name\n",
    "    model_dict[\"layers\"] = []\n",
    "\n",
    "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
    "    for line in lines[1:]:\n",
    "        line = line.strip()\n",
    "        match = layer_regex.match(line)\n",
    "        if match:\n",
    "            index, layer = match.groups()\n",
    "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
    "    return model_dict\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "def get_predictions(model, eval_data, step=10):\n",
    "\n",
    "    predicted_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, len(eval_data), step):\n",
    "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader):\n",
    "    predicted_labels = []\n",
    "    real_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            y_predicted = model(batch[0].to(device))\n",
    "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
    "            real_labels.append(batch[1])\n",
    "\n",
    "    predicted_labels = torch.cat(predicted_labels)\n",
    "    real_labels = torch.cat(real_labels)\n",
    "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
    "    return accuracy_score\n",
    "\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-22 22:09:16--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
      "--2025-04-22 22:09:18--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8002::154, 2606:50c0:8001::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6272446 (6.0M) [application/octet-stream]\n",
      "Saving to: ‘hw_overfitting_data_dict.npy’\n",
      "\n",
      "hw_overfitting_data 100%[===================>]   5.98M   153KB/s    in 44s     \n",
      "\n",
      "2025-04-22 22:10:02 (140 KB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zeA6Q5-CgSq7"
   },
   "source": [
    "### Задача №1 (уже решённая): Создание и обучение модели (Separation)\n",
    "Вы уже решали эту задачу ранее, так что сейчас просто воспроизведите своё решение. Оно понадобится вам в дальнейших шагах.\n",
    "__Ваша первая задача всё та же: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEVICE_ID = 0  # change if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nPG1KbQAgl8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "device = (\n",
    "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    ")\n",
    "# __________end of block__________\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "aYcL28OsgSq8",
    "outputId": "93aafa07-fb56-43bd-f928-918f45fe30e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/train-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Image label: 9')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "\n",
    "train_fmnist_data = FashionMNIST(\n",
    "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "test_fmnist_data = FashionMNIST(\n",
    "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
    ")\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "random_batch = next(iter(train_data_loader))\n",
    "_image, _label = random_batch[0][0], random_batch[1][0]\n",
    "plt.figure()\n",
    "plt.imshow(_image.reshape(28, 28))\n",
    "plt.title(f\"Image label: {_label}\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6jWRv1rgSq8"
   },
   "source": [
    "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
    "\n",
    "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BcyEFX-RgSq8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Flatten(start_dim=1, end_dim=-1)\n",
       "    (4): Linear(in_features=50176, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating model instance\n",
    "model_task_1 = None\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            #nn.Linear(28*28, 512)\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*28*28, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model_task_1 = NeuralNetwork().to(device)\n",
    "display(model_task_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAoLV4dkoy5M"
   },
   "source": [
    "Не забудьте перенести модель на выбранный `device`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Xas9SIXDoxvZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Flatten(start_dim=1, end_dim=-1)\n",
       "    (4): Linear(in_features=50176, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_task_1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pLRWysggSq9"
   },
   "source": [
    "Локальные тесты для проверки вашей модели доступны ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qMQzo1ggSq9",
    "outputId": "c00008eb-ef88-4000-ce47-e8dedd26e061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything seems fine!\n"
     ]
    }
   ],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
    "\n",
    "try:\n",
    "    x = random_batch[0].to(device)\n",
    "    y = random_batch[1].to(device)\n",
    "\n",
    "    # compute outputs given inputs, both are variables\n",
    "    y_predicted = model_task_1(x)\n",
    "except Exception as e:\n",
    "    print(\"Something is wrong with the model\")\n",
    "    raise e\n",
    "\n",
    "\n",
    "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
    "\n",
    "print(\"Everything seems fine!\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suRmIPwIgSq9"
   },
   "source": [
    "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YJnU14bdnZa_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.317875  [   32/60000]\n",
      "loss: 0.619712  [ 3232/60000]\n",
      "loss: 0.662156  [ 6432/60000]\n",
      "loss: 0.556197  [ 9632/60000]\n",
      "loss: 0.461102  [12832/60000]\n",
      "loss: 0.293362  [16032/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_task_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     test(test_data_loader, model_task_1, loss_fn)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/mlhw1/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlhw1/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlhw1/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "import torch.optim.sgd\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_task_1.parameters(), lr=0.01)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "print(1e-1)\n",
    "epochs = 15 # 20 -> 0,91 0,883\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_data_loader, model_task_1, loss_fn, optimizer)\n",
    "    test(test_data_loader, model_task_1, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zce7gt1gSq-"
   },
   "source": [
    "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usswrWYOgSq-"
   },
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Xua3TVZHgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on train set: 0.0458\n"
     ]
    }
   ],
   "source": [
    "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "l9KEKXBxgSq-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network accuracy on test set: 0.0455\n"
     ]
    }
   ],
   "source": [
    "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oyhmMobgSq_"
   },
   "source": [
    "Проверка, что необходимые пороги пройдены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "OAIrURCEgSq_",
    "outputId": "7c983690-a92e-4693-89fb-7c86c002921a"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Train accuracy is below 0.885 threshold",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m test_acc_task_1 \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.885\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain accuracy is below 0.885 threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     train_acc_task_1 \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.905\u001b[39m\n\u001b[1;32m      4\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Train accuracy is below 0.885 threshold"
     ]
    }
   ],
   "source": [
    "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
    "assert (\n",
    "    train_acc_task_1 >= 0.905\n",
    "), \"Test accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict = {\n",
    "    \"train_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "    ),\n",
    "    \"test_predictions_task_1\": get_predictions(\n",
    "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "    ),\n",
    "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
    "}\n",
    "\n",
    "with open(\"submission_dict_task_1.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_task_1.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №2: Переобучение (Initiation)\n",
    "Продолжим работу с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Теперь ваша задача продемонстрировать переобучение модели на обучающей выборке. Достаточно показать, что точность классификации (не только функция потерь!) на тестовой выборке значительно отстает от обучающей.\n",
    "\n",
    "Обращаем ваше внимание, в задаче №3 вам придется починить данную модель (минимизировать эффект переобучения) с помощью механизмов регуляризации, поэтому не переусердствуйте!\n",
    "\n",
    "__Ваша вторая задача: реализовать используя пайплан обучения модели продемонстрировать переобучения модели на обучающей выборке.__\n",
    "\n",
    "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимание, вам необходимо использовать переменную `model_task_2` для хранение модели во второй задаче. \n",
    "\n",
    "Не используйте `Dropout` и `BatchNorm` в этой задаче"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model instance\n",
    "model_task_2 = None\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка архитектуры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "layers_task_2 = []\n",
    "for element in parse_pytorch_model(str(model_task_2)).get(\"layers\", []):\n",
    "    layer_name = element[\"layer\"][\"type\"]\n",
    "    assert \"dropout\" not in layer_name.lower(), \"Do not use Dropout in Task 2!\"\n",
    "    assert \"batchnorm\" not in layer_name.lower(), \"Do not use BatchNorm in Task 2!\"\n",
    "    layers_task_2.append(layer_name)\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_task_2 = get_accuracy(model_task_2, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_2:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_task_2 = get_accuracy(model_task_2, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_2:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что переобучение присутствует:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_acc_task_2 >= test_acc_task_2, \"Train accuracy must be higher than task accuracy\"\n",
    "assert train_acc_task_2 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
    "assert (\n",
    "    train_acc_task_2 - test_acc_task_2 >= 0.04\n",
    "), \"Test accuracy should be at least 0.04 lower that train.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_2`.\n",
    "\n",
    "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задачи №1. Если их там нет, загрузите их из сохраненного файла в переменную перед запуском следующей ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict.update(\n",
    "    {\n",
    "        \"train_predictions_task_2\": get_predictions(\n",
    "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "        ),\n",
    "        \"test_predictions_task_2\": get_predictions(\n",
    "            model_task_2, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "        ),\n",
    "        \"model_task_2\": parse_pytorch_model(str(model_task_2)),\n",
    "    }\n",
    ")\n",
    "\n",
    "with open(\"submission_dict_tasks_1_and_2.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_tasks_1_and_2.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №3: Исправление модели (Return) \n",
    "Все так же работаем с [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Наконец, ваша задача исправить ~~ошибки прошлого~~ переобучение модели, построенной в задаче 2. Достаточно добиться расхождения между точностью классификации на обучающей и тестовой выборках не превышающего 0.015 (т.е. полутора процентов).\n",
    "\n",
    "Обращаем ваше внимание, архитектура модели в задаче №3 не должна существенно отличаться от задачи №2! Вы можете использовать Batchnorm, Dropout, уменьшить размерность промежуточных представлений, обратиться к аугментации данных, но вы не можете использовать меньшее количество слоёв.\n",
    "\n",
    "__Ваша третья и финальная задача: исправить модель и/или процесс обучения, дабы справиться с переобучением.__\n",
    "\n",
    "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимание, вам необходимо использовать переменную `model_task_3` для хранение модели во второй задаче. \n",
    "\n",
    "Также код ниже будет обращаться к переменной `layers_task_2`, инициализируйте её, если она не определена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert (\n",
    "    layers_task_2 is not None\n",
    "), \"Initializa layers_task_2 vairable which contains list of layers in task 2 model\"\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_task_3 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка архитектуры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "layers_task_3 = []\n",
    "for element in parse_pytorch_model(str(model_task_3)).get(\"layers\", []):\n",
    "    layer_name = element[\"layer\"][\"type\"]\n",
    "    layers_task_3.append(layer_name)\n",
    "\n",
    "\n",
    "idx = 0\n",
    "for model_3_layer in layers_task_3:\n",
    "    model_2_layer = layers_task_2[idx]\n",
    "    if \"dropout\" not in model_3_layer.lower() and \"batchnorm\" not in model_3_layer.lower():\n",
    "        assert (\n",
    "            model_3_layer == model_2_layer\n",
    "        ), \"Models in tasks 2 and 3 must share the architecture except for Dropout and BatchNorm!\"\n",
    "        idx += 1\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество классификации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_task_3 = get_accuracy(model_task_3, train_data_loader)\n",
    "print(f\"Neural network accuracy on train set: {train_acc_task_3:3.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_task_3 = get_accuracy(model_task_3, test_data_loader)\n",
    "print(f\"Neural network accuracy on test set: {test_acc_task_3:3.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка, что переобучение присутствует:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_acc_task_3 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
    "assert train_acc_task_3 >= 0.865, \"Test accuracy must be higher than 0.865\"\n",
    "assert (\n",
    "    train_acc_task_3 - test_acc_task_3 <= 0.015\n",
    "), \"Test accuracy should not be lower that train more than by 0.015\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_3`.\n",
    "\n",
    "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задач №1 и №2. Если их там нет, загрузите их из сохраненных файлов перед запуском следующей ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not change the code in the block below\n",
    "# __________start of block__________\n",
    "assert os.path.exists(\n",
    "    \"hw_overfitting_data_dict.npy\"\n",
    "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
    "\n",
    "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
    "\n",
    "submission_dict.update(\n",
    "    {\n",
    "        \"train_predictions_task_3\": get_predictions(\n",
    "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
    "        ),\n",
    "        \"test_predictions_task_3\": get_predictions(\n",
    "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
    "        ),\n",
    "        \"model_task_3\": parse_pytorch_model(str(model_task_3)),\n",
    "    }\n",
    ")\n",
    "\n",
    "with open(\"submission_dict_final.json\", \"w\") as iofile:\n",
    "    json.dump(submission_dict, iofile)\n",
    "print(\"File saved to `submission_dict_final.json`\")\n",
    "# __________end of block__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xai8JL3tgSq_"
   },
   "source": [
    "### Сдача задания\n",
    "Сдайте сгенерированные файлы в соответствующие задачи в соревновании, а именно:\n",
    "* `submission_dict_tasks_1_and_2.json` в задачу Initiation\n",
    "* `submission_dict_final.json` в задачу Return.\n",
    "\n",
    "\n",
    "`submission_dict_task_1.json` сдавать не нужно, он уже был сдан ранее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtWnYAN_gSrA"
   },
   "source": [
    "На этом задание завершено. Поздравляем!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlhw1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
